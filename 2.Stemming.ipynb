{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbf6ebd5",
   "metadata": {},
   "source": [
    "## Porter Stemmer \n",
    "Stemming is the process of reducing a word to its word stem, which may involve removing affixes, suffixes, or prefixes to reach the root of the word, known as the lemma. This process is crucial in natural language understanding and processing.\n",
    "\n",
    "For example, words like \"eating,\" \"eat,\" and \"eaten\" share the root word \"eat.\" Similarly, \"going,\" \"gone,\" and \"goes\" share the root \"go.\" Stemming helps consolidate these variations into a single form, reducing the number of unique input features in text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94a54e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7cf0d5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['eating', 'eats', 'eaten', 'writing', 'writes', 'programming', 'programs', 'history', 'finally', 'finalized']\n",
    "stemming = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c505f1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating--->eat\n",
      "eats--->eat\n",
      "eaten--->eaten\n",
      "writing--->write\n",
      "writes--->write\n",
      "programming--->program\n",
      "programs--->program\n",
      "history--->histori\n",
      "finally--->final\n",
      "finalized--->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"--->\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5588bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stemming can sometimes alter the meaning of words or produce stems that are not actual words. \\nFor example, stemming \"congratulations\" might yield \"congratul\" which is not a valid word. \\nThis is a major disadvantage of stemming, as it can distort the original meaning.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')\n",
    "\"\"\"Stemming can sometimes alter the meaning of words or produce stems that are not actual words. \n",
    "For example, stemming \"congratulations\" might yield \"congratul\" which is not a valid word. \n",
    "This is a major disadvantage of stemming, as it can distort the original meaning.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75caab0",
   "metadata": {},
   "source": [
    "## Regexpstemmer\n",
    "Another stemming technique is the Regular Expression Stemmer, which removes prefixes or suffixes matching a given regular expression. This allows custom control over which parts of words are removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "954ded6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4f4c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_stemmer= RegexpStemmer('ing$|s$|e$|able$', min=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a62104c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d29211",
   "metadata": {},
   "source": [
    "## Snowball Stemmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98736aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "643089a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowballStemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23313270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating---->eat\n",
      "eats---->eat\n",
      "eaten---->eaten\n",
      "writing---->write\n",
      "writes---->write\n",
      "programming---->program\n",
      "programs---->program\n",
      "history---->histori\n",
      "finally---->final\n",
      "finalized---->final\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"---->\"+snowballStemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c455af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fairli', 'sportingli')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem(\"fairly\"),stemming.stem(\"sportingly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "670e05a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('fair', 'sport')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowballStemmer.stem('fairly'), snowballStemmer.stem(\"sportingly\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
